!conda env list


!conda activate pyspark_env



!pip install pyspark


import pyspark


import pandas as pd
df = pd.read_csv('test1.csv')
df





from pyspark.sql import SparkSession


spark = SparkSession.builder.appName('Practice').getOrCreate()


spark





df_spark = spark.read.csv('test1.csv')
df_spark


df_spark.show()


# using header row.


df_spark = spark.read.option('header',True).csv('test1.csv')
df_spark


df_spark.show()





type(df_spark)





df_spark.head(5) # note: we need to provide the number of rows we want it to display





df_spark.printSchema()



